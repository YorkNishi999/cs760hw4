{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9d57cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import japanize_matplotlib\n",
    "from IPython.display import display\n",
    "\n",
    "# torch library\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchinfo import summary\n",
    "from torchviz import make_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0803a397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # warning表示off\n",
    "# import warnings\n",
    "# warnings.simplefilter('ignore')\n",
    "\n",
    "# # デフォルトフォントサイズ変更\n",
    "# plt.rcParams['font.size'] = 14\n",
    "\n",
    "# # デフォルトグラフサイズ変更\n",
    "# plt.rcParams['figure.figsize'] = (6,6)\n",
    "\n",
    "# # デフォルトで方眼表示ON\n",
    "# plt.rcParams['axes.grid'] = True\n",
    "\n",
    "# # numpyの表示桁数設定\n",
    "# np.set_printoptions(suppress=True, precision=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9128737f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c71b634",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.datasets as datasets\n",
    "\n",
    "# data direct\n",
    "data_root = './data'\n",
    "\n",
    "train_set0 = datasets.MNIST(\n",
    "    root = data_root,  \n",
    "    train = True,  \n",
    "    download = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e9af176",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "# データ変換用関数 Transforms\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    # (1) to tensor\n",
    "    transforms.ToTensor(),\n",
    "    \n",
    "    # (2) normalize\n",
    "    transforms.Normalize(0.5, 0.5),\n",
    "    \n",
    "    # (3) to 1 tensor\n",
    "    transforms.Lambda(lambda x: x.view(-1)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b99e7d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データ取得用関数 Dataset\n",
    "\n",
    "# train data\n",
    "train_set = datasets.MNIST(\n",
    "    root = data_root, train = True,\n",
    "    download = True, transform = transform)\n",
    "\n",
    "# test data\n",
    "test_set = datasets.MNIST(\n",
    "    root = data_root, train = False, \n",
    "    download = True, transform = transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aceeae94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# batch size\n",
    "batch_size = 100\n",
    "\n",
    "# train dataloader with shuffle\n",
    "train_loader = DataLoader(\n",
    "    train_set, batch_size = batch_size, \n",
    "    shuffle = True)\n",
    "\n",
    "# test dataloader\n",
    "test_loader = DataLoader(\n",
    "    test_set,  batch_size = batch_size, \n",
    "    shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95476db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels in train_loader:\n",
    "    break\n",
    "\n",
    "for i in range(20):\n",
    "    # numpy\n",
    "    image = images[i].numpy()\n",
    "    label = labels[i]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d479f7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_input: 784  n_hidden: 50 n_output: 10\n"
     ]
    }
   ],
   "source": [
    "# deg of input\n",
    "n_input = image.shape[0]\n",
    "\n",
    "# deg of output\n",
    "# the num of classes\n",
    "n_output = len(set(list(labels.data.numpy())))\n",
    "\n",
    "#   # of hidden node\n",
    "n_hidden = 50\n",
    "\n",
    "# print hyperparameters\n",
    "print(f'n_input: {n_input}  n_hidden: {n_hidden} n_output: {n_output}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9cddcfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "# in: 784 out:10 hidden: 1 layer\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, n_input, n_output, n_hidden):\n",
    "        super().__init__()\n",
    "\n",
    "        # hidden\n",
    "        self.l1 = nn.Linear(n_input, n_hidden)\n",
    "\n",
    "        # Sigmoid\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "        # output\n",
    "        self.l2 = nn.Linear(n_hidden, n_output)\n",
    "\n",
    "\n",
    "   \n",
    "    def forward(self, x):\n",
    "        x1 = self.l1(x)\n",
    "        x2 = self.sigmoid(x1)\n",
    "        x3 = self.l2(x2)\n",
    "        return x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f48dd306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model instance\n",
    "net = Net(n_input, n_output, n_hidden).to(device)\n",
    "\n",
    "# loss function: cross entropy\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# optimizer\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.1)\n",
    "\n",
    "# epoch\n",
    "num_epochs = 30\n",
    "\n",
    "# record result\n",
    "history = np.zeros((0,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60d4ea91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30], loss: 0.84618 acc: 0.80880 val_loss: 0.40428, val_acc: 0.89490\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/vc/tp1zsmgj3bs50p2b5cq190w80000gn/T/ipykernel_2601/2703009638.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mn_train\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_py3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_py3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_py3/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_py3/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_py3/lib/python3.7/site-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_py3/lib/python3.7/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_py3/lib/python3.7/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \"\"\"\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \"\"\"\n\u001b[1;32m     98\u001b[0m         \u001b[0mArgs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# loop\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_acc, train_loss = 0, 0\n",
    "    val_acc, val_loss = 0, 0\n",
    "    n_train, n_test = 0, 0\n",
    "\n",
    "    # training\n",
    "    for inputs, labels in train_loader:\n",
    "        n_train += len(labels)\n",
    "\n",
    "        # device\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "    \n",
    "        # init grad\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # calc output\n",
    "        outputs = net(inputs)\n",
    "\n",
    "        # calc loss\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # grad backward\n",
    "        loss.backward()\n",
    "    \n",
    "        # modify parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # predict labels\n",
    "        predicted = torch.max(outputs, 1)[1]\n",
    "\n",
    "        # calc loss and accuracy\n",
    "        train_loss += loss.item()\n",
    "        train_acc += (predicted == labels).sum() \n",
    "\n",
    "    # predict\n",
    "    for inputs_test, labels_test in test_loader:\n",
    "        n_test += len(labels_test)\n",
    "\n",
    "        inputs_test = inputs_test.to(device)\n",
    "        labels_test = labels_test.to(device)\n",
    "\n",
    "            \n",
    "        # calc output\n",
    "        outputs_test = net(inputs_test)\n",
    "\n",
    "        # calc loss\n",
    "        loss_test = criterion(outputs_test, labels_test)\n",
    "\n",
    "        # output pred\n",
    "        predicted_test = torch.max(outputs_test, 1)[1]\n",
    "\n",
    "        # calc loss and accu\n",
    "        val_loss +=  loss_test.item()\n",
    "        val_acc +=  (predicted_test == labels_test).sum()\n",
    "\n",
    "    # calc metrics and recode them\n",
    "    train_acc = train_acc / n_train\n",
    "    val_acc = val_acc / n_test\n",
    "    train_loss = train_loss * batch_size / n_train\n",
    "    val_loss = val_loss * batch_size / n_test\n",
    "    print (f'Epoch [{epoch+1}/{num_epochs}], loss: {train_loss:.5f} acc: {train_acc:.5f} val_loss: {val_loss:.5f}, val_acc: {val_acc:.5f}')\n",
    "    item = np.array([epoch+1 , train_loss, train_acc, val_loss, val_acc])\n",
    "    history = np.vstack((history, item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3953aa7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning curve\n",
    "plt.rcParams['axes.grid'] = False\n",
    "plt.rcParams['figure.figsize'] = (9,8)\n",
    "plt.plot(history[:,0], history[:,1], 'b', label='training')\n",
    "plt.xlabel('recursion')\n",
    "plt.ylabel('loss')\n",
    "plt.title('Learning curve (loss)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edde3f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test error\n",
    "\n",
    "plt.rcParams['axes.grid'] = False\n",
    "plt.rcParams['figure.figsize'] = (9,8)\n",
    "plt.plot(history[:,0], 1-history[:,4], 'b', label='test')\n",
    "plt.xlabel('recursion')\n",
    "plt.ylabel('Error')\n",
    "plt.title('Test error')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5e4745",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
